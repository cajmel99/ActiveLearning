{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'car.data'\n",
    "df = pd.read_csv(os.path.join(os.getcwd(), 'car+evaluation', file_name), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "df.columns = columns_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety  class\n",
       "0  vhigh  vhigh     2       2    small    low  unacc\n",
       "1  vhigh  vhigh     2       2    small    med  unacc\n",
       "2  vhigh  vhigh     2       2    small   high  unacc\n",
       "3  vhigh  vhigh     2       2      med    low  unacc\n",
       "4  vhigh  vhigh     2       2      med    med  unacc"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      0\n",
       "maint       0\n",
       "doors       0\n",
       "persons     0\n",
       "lug_boot    0\n",
       "safety      0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1728 entries, 0 to 1727\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   buying    1728 non-null   object\n",
      " 1   maint     1728 non-null   object\n",
      " 2   doors     1728 non-null   object\n",
      " 3   persons   1728 non-null   object\n",
      " 4   lug_boot  1728 non-null   object\n",
      " 5   safety    1728 non-null   object\n",
      " 6   class     1728 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 94.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "unacc    1210\n",
       "acc       384\n",
       "good       69\n",
       "vgood      65\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_lowest_probabieties(probalility, df, n_samples, labels):\n",
    "    \"\"\"\n",
    "    Split df for 2 df, where df_top contains the rows with the lowest probabilities, and df_rest contains the rest of the rows.\n",
    "    \"\"\"\n",
    "    df_with_proba = df.copy()\n",
    "    df_with_proba['probability'] = None\n",
    "    df_with_proba['labels'] = None\n",
    "\n",
    "    df_with_proba['probability'] = probalility\n",
    "    df_with_proba['labels'] = labels\n",
    "    df_with_proba = df_with_proba.sort_values(by='probability', ascending=True)\n",
    "    df_top = df_with_proba[:n_samples]\n",
    "    X_top = df_top.drop(columns=['probability', 'labels'])\n",
    "    y_top = df_top['labels']\n",
    "    df_rest = df_with_proba[n_samples:]\n",
    "    X_rest = df_rest.drop(columns=['probability', 'labels'])\n",
    "    y_rest = df_rest['labels']\n",
    "\n",
    "    return X_top, y_top, X_rest, y_rest\n",
    "\n",
    "def save_metrics_to_file(filename, cycle, precision, recall, f1, cm, accuracy, X_labelled, y_test):\n",
    "    # Create a list to hold the results for this cycle\n",
    "    results = []\n",
    "    \n",
    "    # Append results for each class in the metrics\n",
    "    for i, class_label in enumerate(np.unique(y_test)):\n",
    "        results.append({\n",
    "            'Cycle': cycle,\n",
    "            'Class': class_label,\n",
    "            'Precision': precision[i],\n",
    "            'Recall': recall[i],\n",
    "            'F1-score': f1[i],\n",
    "            'Accuracy': accuracy,\n",
    "            'Confusion Matrix': cm.tolist(),\n",
    "            'Labelled Samples': X_labelled.shape[0]\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Append to the CSV file (if it exists) or create a new one\n",
    "    results_df.to_csv(filename, mode='a', header=not pd.io.common.file_exists(filename), index=False)\n",
    "    print(f\"Metrics saved for cycle {cycle} to {filename}\")\n",
    "    \n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return precision, recall, f1, cm, accuracy\n",
    "\n",
    "def select_samples(probalility, df, n_samples, labels, metric=\"least_confidence\"):\n",
    "    \"\"\"\n",
    "    Select samples for active learning based on different uncertainty metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    - probalility: Array of probabilities for each sample (shape: [n_samples, n_classes]).\n",
    "    - df: The DataFrame containing the feature data.\n",
    "    - n_samples: The number of samples to select.\n",
    "    - labels: The true labels for the unlabelled samples.\n",
    "    - metric: The uncertainty metric to use. Options are 'least_confidence', 'entropy', or 'margin_sampling'.\n",
    "    \n",
    "    Returns:\n",
    "    - X_top: The feature data for the selected samples.\n",
    "    - y_top: The labels for the selected samples.\n",
    "    - X_rest: The feature data for the remaining samples.\n",
    "    - y_rest: The labels for the remaining samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a DataFrame to store the probabilities and labels\n",
    "    df_with_proba = df.copy()\n",
    "    df_with_proba['labels'] = labels\n",
    "\n",
    "    # Compute the uncertainty scores based on the chosen metric\n",
    "    if metric == \"least_confidence\":\n",
    "        # Least Confidence: Select the samples with the lowest top predicted probabilities\n",
    "        prob_top = np.max(probalility, axis=1)  # Get the top probability for each sample\n",
    "        df_with_proba['uncertainty'] = prob_top\n",
    "\n",
    "    elif metric == \"entropy\":\n",
    "        # Entropy: Calculate the entropy for each sample based on its class probabilities\n",
    "        entropy_values = -np.sum(probalility * np.log(probalility + 1e-10), axis=1)  # Adding small epsilon to avoid log(0)\n",
    "        df_with_proba['uncertainty'] = entropy_values\n",
    "\n",
    "    elif metric == \"margin_sampling\":\n",
    "        # Margin Sampling: Select the samples where the top two predicted probabilities are closest\n",
    "        top_2_probs = np.partition(probalility, -2, axis=1)[:, -2:]  # Get the top 2 predicted probabilities\n",
    "        margin = top_2_probs[:, 1] - top_2_probs[:, 0]  # Calculate the difference between the top two\n",
    "        df_with_proba['uncertainty'] = margin\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown metric: {metric}. Available options are 'least_confidence', 'entropy', 'margin_sampling'.\")\n",
    "    \n",
    "    # Sort the samples by the uncertainty (ascending order to get the most uncertain samples)\n",
    "    df_with_proba = df_with_proba.sort_values(by='uncertainty', ascending=True)\n",
    "    \n",
    "    # Select the top `n_samples` samples with the highest uncertainty\n",
    "    df_top = df_with_proba[:n_samples]\n",
    "    X_top = df_top.drop(columns=['uncertainty', 'labels'])\n",
    "    y_top = df_top['labels']\n",
    "    \n",
    "    # Select the remaining samples\n",
    "    df_rest = df_with_proba[n_samples:]\n",
    "    X_rest = df_rest.drop(columns=['uncertainty', 'labels'])\n",
    "    y_rest = df_rest['labels']\n",
    "    \n",
    "    return X_top, y_top, X_rest, y_rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved for cycle 0 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.6522, Recall=0.5844, F1-score=0.6164\n",
      "Class good: Precision=0.1250, Recall=0.0714, F1-score=0.0909\n",
      "Class unacc: Precision=0.8984, Recall=0.9504, F1-score=0.9237\n",
      "Class vgood: Precision=0.2308, Recall=0.2308, F1-score=0.2308\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 45   2  22   8]\n",
      " [  8   1   3   2]\n",
      " [ 12   0 230   0]\n",
      " [  4   5   1   3]]\n",
      "\n",
      "Overall Accuracy: 0.8064\n",
      "188\n",
      "Metrics saved for cycle 1 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.6557, Recall=0.5195, F1-score=0.5797\n",
      "Class good: Precision=0.1818, Recall=0.1429, F1-score=0.1600\n",
      "Class unacc: Precision=0.9291, Recall=0.9752, F1-score=0.9516\n",
      "Class vgood: Precision=0.3000, Recall=0.4615, F1-score=0.3636\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 40   7  17  13]\n",
      " [ 10   2   1   1]\n",
      " [  6   0 236   0]\n",
      " [  5   2   0   6]]\n",
      "\n",
      "Overall Accuracy: 0.8208\n",
      "238\n",
      "Metrics saved for cycle 2 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.6176, Recall=0.5455, F1-score=0.5793\n",
      "Class good: Precision=0.2222, Recall=0.1429, F1-score=0.1739\n",
      "Class unacc: Precision=0.9157, Recall=0.9421, F1-score=0.9287\n",
      "Class vgood: Precision=0.3000, Recall=0.4615, F1-score=0.3636\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 42   5  18  12]\n",
      " [  8   2   2   2]\n",
      " [ 12   2 228   0]\n",
      " [  6   0   1   6]]\n",
      "\n",
      "Overall Accuracy: 0.8035\n",
      "288\n",
      "Metrics saved for cycle 3 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.7302, Recall=0.5974, F1-score=0.6571\n",
      "Class good: Precision=0.2727, Recall=0.2143, F1-score=0.2400\n",
      "Class unacc: Precision=0.9325, Recall=0.9711, F1-score=0.9514\n",
      "Class vgood: Precision=0.2500, Recall=0.3846, F1-score=0.3030\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 46   5  15  11]\n",
      " [  5   3   2   4]\n",
      " [  7   0 235   0]\n",
      " [  5   3   0   5]]\n",
      "\n",
      "Overall Accuracy: 0.8353\n",
      "338\n",
      "Metrics saved for cycle 4 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.7297, Recall=0.7013, F1-score=0.7152\n",
      "Class good: Precision=0.2222, Recall=0.1429, F1-score=0.1739\n",
      "Class unacc: Precision=0.9206, Recall=0.9587, F1-score=0.9393\n",
      "Class vgood: Precision=0.4545, Recall=0.3846, F1-score=0.4167\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 54   3  17   3]\n",
      " [  7   2   2   3]\n",
      " [ 10   0 232   0]\n",
      " [  3   4   1   5]]\n",
      "\n",
      "Overall Accuracy: 0.8468\n",
      "388\n",
      "Metrics saved for cycle 5 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.7838, Recall=0.7532, F1-score=0.7682\n",
      "Class good: Precision=0.1818, Recall=0.1429, F1-score=0.1600\n",
      "Class unacc: Precision=0.9435, Recall=0.9669, F1-score=0.9551\n",
      "Class vgood: Precision=0.5385, Recall=0.5385, F1-score=0.5385\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 58   5  13   1]\n",
      " [  7   2   0   5]\n",
      " [  7   1 234   0]\n",
      " [  2   3   1   7]]\n",
      "\n",
      "Overall Accuracy: 0.8699\n",
      "438\n",
      "Metrics saved for cycle 6 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.6747, Recall=0.7273, F1-score=0.7000\n",
      "Class good: Precision=0.2000, Recall=0.1429, F1-score=0.1667\n",
      "Class unacc: Precision=0.9461, Recall=0.9421, F1-score=0.9441\n",
      "Class vgood: Precision=0.4167, Recall=0.3846, F1-score=0.4000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 56   5  13   3]\n",
      " [  9   2   0   3]\n",
      " [ 12   1 228   1]\n",
      " [  6   2   0   5]]\n",
      "\n",
      "Overall Accuracy: 0.8410\n",
      "488\n",
      "Metrics saved for cycle 7 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.7368, Recall=0.7273, F1-score=0.7320\n",
      "Class good: Precision=0.3333, Recall=0.3571, F1-score=0.3448\n",
      "Class unacc: Precision=0.9426, Recall=0.9504, F1-score=0.9465\n",
      "Class vgood: Precision=0.6364, Recall=0.5385, F1-score=0.5833\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 56   5  14   2]\n",
      " [  7   5   0   2]\n",
      " [ 11   1 230   0]\n",
      " [  2   4   0   7]]\n",
      "\n",
      "Overall Accuracy: 0.8613\n",
      "538\n",
      "Metrics saved for cycle 8 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.7821, Recall=0.7922, F1-score=0.7871\n",
      "Class good: Precision=0.4000, Recall=0.2857, F1-score=0.3333\n",
      "Class unacc: Precision=0.9435, Recall=0.9669, F1-score=0.9551\n",
      "Class vgood: Precision=0.7000, Recall=0.5385, F1-score=0.6087\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 61   2  13   1]\n",
      " [  7   4   1   2]\n",
      " [  8   0 234   0]\n",
      " [  2   4   0   7]]\n",
      "\n",
      "Overall Accuracy: 0.8844\n",
      "588\n",
      "Metrics saved for cycle 9 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8714, Recall=0.7922, F1-score=0.8299\n",
      "Class good: Precision=0.5833, Recall=0.5000, F1-score=0.5385\n",
      "Class unacc: Precision=0.9407, Recall=0.9835, F1-score=0.9616\n",
      "Class vgood: Precision=0.7273, Recall=0.6154, F1-score=0.6667\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 61   1  14   1]\n",
      " [  4   7   1   2]\n",
      " [  4   0 238   0]\n",
      " [  1   4   0   8]]\n",
      "\n",
      "Overall Accuracy: 0.9075\n",
      "638\n",
      "Metrics saved for cycle 10 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8378, Recall=0.8052, F1-score=0.8212\n",
      "Class good: Precision=0.7500, Recall=0.6429, F1-score=0.6923\n",
      "Class unacc: Precision=0.9444, Recall=0.9835, F1-score=0.9636\n",
      "Class vgood: Precision=0.7500, Recall=0.4615, F1-score=0.5714\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 62   0  14   1]\n",
      " [  4   9   0   1]\n",
      " [  4   0 238   0]\n",
      " [  4   3   0   6]]\n",
      "\n",
      "Overall Accuracy: 0.9104\n",
      "688\n",
      "Metrics saved for cycle 11 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8182, Recall=0.8182, F1-score=0.8182\n",
      "Class good: Precision=0.8571, Recall=0.4286, F1-score=0.5714\n",
      "Class unacc: Precision=0.9562, Recall=0.9917, F1-score=0.9736\n",
      "Class vgood: Precision=0.6364, Recall=0.5385, F1-score=0.5833\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 63   1  11   2]\n",
      " [  6   6   0   2]\n",
      " [  2   0 240   0]\n",
      " [  6   0   0   7]]\n",
      "\n",
      "Overall Accuracy: 0.9133\n",
      "738\n",
      "Metrics saved for cycle 12 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8788, Recall=0.7532, F1-score=0.8112\n",
      "Class good: Precision=0.6923, Recall=0.6429, F1-score=0.6667\n",
      "Class unacc: Precision=0.9373, Recall=0.9876, F1-score=0.9618\n",
      "Class vgood: Precision=0.5833, Recall=0.5385, F1-score=0.5600\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 58   0  16   3]\n",
      " [  3   9   0   2]\n",
      " [  3   0 239   0]\n",
      " [  2   4   0   7]]\n",
      "\n",
      "Overall Accuracy: 0.9046\n",
      "788\n",
      "Metrics saved for cycle 13 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8571, Recall=0.7792, F1-score=0.8163\n",
      "Class good: Precision=0.4286, Recall=0.4286, F1-score=0.4286\n",
      "Class unacc: Precision=0.9597, Recall=0.9835, F1-score=0.9714\n",
      "Class vgood: Precision=0.4286, Recall=0.4615, F1-score=0.4444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 60   4  10   3]\n",
      " [  3   6   0   5]\n",
      " [  4   0 238   0]\n",
      " [  3   4   0   6]]\n",
      "\n",
      "Overall Accuracy: 0.8960\n",
      "838\n",
      "Metrics saved for cycle 14 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8667, Recall=0.8442, F1-score=0.8553\n",
      "Class good: Precision=0.6667, Recall=0.5714, F1-score=0.6154\n",
      "Class unacc: Precision=0.9673, Recall=0.9793, F1-score=0.9733\n",
      "Class vgood: Precision=0.5714, Recall=0.6154, F1-score=0.5926\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 65   2   8   2]\n",
      " [  2   8   0   4]\n",
      " [  5   0 237   0]\n",
      " [  3   2   0   8]]\n",
      "\n",
      "Overall Accuracy: 0.9191\n",
      "888\n",
      "Metrics saved for cycle 15 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.9067, Recall=0.8831, F1-score=0.8947\n",
      "Class good: Precision=0.7000, Recall=0.5000, F1-score=0.5833\n",
      "Class unacc: Precision=0.9676, Recall=0.9876, F1-score=0.9775\n",
      "Class vgood: Precision=0.5000, Recall=0.5385, F1-score=0.5185\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 68   0   7   2]\n",
      " [  2   7   0   5]\n",
      " [  3   0 239   0]\n",
      " [  2   3   1   7]]\n",
      "\n",
      "Overall Accuracy: 0.9277\n",
      "938\n",
      "Metrics saved for cycle 16 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.9189, Recall=0.8831, F1-score=0.9007\n",
      "Class good: Precision=0.9091, Recall=0.7143, F1-score=0.8000\n",
      "Class unacc: Precision=0.9597, Recall=0.9835, F1-score=0.9714\n",
      "Class vgood: Precision=0.6923, Recall=0.6923, F1-score=0.6923\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 68   0   7   2]\n",
      " [  1  10   1   2]\n",
      " [  4   0 238   0]\n",
      " [  1   1   2   9]]\n",
      "\n",
      "Overall Accuracy: 0.9393\n",
      "988\n",
      "Metrics saved for cycle 17 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.9189, Recall=0.8831, F1-score=0.9007\n",
      "Class good: Precision=0.8571, Recall=0.8571, F1-score=0.8571\n",
      "Class unacc: Precision=0.9754, Recall=0.9835, F1-score=0.9794\n",
      "Class vgood: Precision=0.7143, Recall=0.7692, F1-score=0.7407\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 68   1   6   2]\n",
      " [  0  12   0   2]\n",
      " [  4   0 238   0]\n",
      " [  2   1   0  10]]\n",
      "\n",
      "Overall Accuracy: 0.9480\n",
      "1038\n",
      "Metrics saved for cycle 18 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8961, Recall=0.8961, F1-score=0.8961\n",
      "Class good: Precision=0.8462, Recall=0.7857, F1-score=0.8148\n",
      "Class unacc: Precision=0.9793, Recall=0.9793, F1-score=0.9793\n",
      "Class vgood: Precision=0.7857, Recall=0.8462, F1-score=0.8148\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 69   1   5   2]\n",
      " [  2  11   0   1]\n",
      " [  5   0 237   0]\n",
      " [  1   1   0  11]]\n",
      "\n",
      "Overall Accuracy: 0.9480\n",
      "1088\n",
      "Metrics saved for cycle 19 to classic_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.9474, Recall=0.9351, F1-score=0.9412\n",
      "Class good: Precision=0.8571, Recall=0.8571, F1-score=0.8571\n",
      "Class unacc: Precision=0.9917, Recall=0.9917, F1-score=0.9917\n",
      "Class vgood: Precision=0.9286, Recall=1.0000, F1-score=0.9630\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 72   2   2   1]\n",
      " [  2  12   0   0]\n",
      " [  2   0 240   0]\n",
      " [  0   0   0  13]]\n",
      "\n",
      "Overall Accuracy: 0.9740\n",
      "1138\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "# Split data to DL and DU\n",
    "X_labelled, X_unlabelled, y_labeled, y_unlabelled = train_test_split(X_train, y_train, test_size=0.9, stratify=y_train)\n",
    "\n",
    "# Prepare data for model\n",
    "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
    "X_labelled = encoder.fit_transform(X_labelled)\n",
    "X_test = encoder.transform(X_test)\n",
    "X_unlabelled = encoder.transform(X_unlabelled)\n",
    "\n",
    "\n",
    "# Whole budget\n",
    "B = 1000\n",
    "# Budget per cycle\n",
    "b = 50\n",
    "# Number of cycle\n",
    "c = 0\n",
    "\n",
    "while B>0:\n",
    "    # Define the model\n",
    "    dt_clf = DecisionTreeClassifier(criterion='gini', max_depth=100, random_state=0)\n",
    "    dt_clf.fit(X_labelled, y_labeled)\n",
    "    probalilities = dt_clf.predict_proba(X_unlabelled)\n",
    "    #X_lowest_prob, y_lowest_proba, X_rest, y_rest = select_lowest_probabieties(probalility=probalilities, df=X_unlabelled, n_samples=b, labels=y_unlabelled)\n",
    "    X_lowest_prob, y_lowest_proba, X_rest, y_rest = select_samples(probalility=probalilities, df=X_unlabelled, n_samples=b, labels=y_unlabelled, metric='margin_sampling')\n",
    "\n",
    "    X_labelled = pd.concat([X_labelled, X_lowest_prob])\n",
    "    y_labeled = pd.concat([y_labeled, y_lowest_proba])\n",
    "    X_unlabelled = X_rest\n",
    "    y_unlabelled = y_rest\n",
    "    # Calculate accuracy for this cycle\n",
    "    y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "    metrics_filename = 'classic_AL.csv'\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, cm, accuracy = calculate_metrics(y_test, y_pred)\n",
    "    \n",
    "    # Save the metrics to the file\n",
    "    save_metrics_to_file(metrics_filename, c, precision, recall, f1, cm, accuracy, X_labelled, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Compute precision, recall, and f1-score for each class\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    \n",
    "    # Print Precision, Recall, and F1 for each class\n",
    "    print(\"Class-wise Precision, Recall, F1-score:\")\n",
    "    for i, class_label in enumerate(np.unique(y_test)):\n",
    "        print(f\"Class {class_label}: Precision={precision[i]:.4f}, Recall={recall[i]:.4f}, F1-score={f1[i]:.4f}\")\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Optionally, you can also print overall accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "    print(X_labelled.shape[0])\n",
    "    c +=1\n",
    "    B -=b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dynamic_class_weights_based_on_model(model, X_labelled, y_labeled):\n",
    "    \"\"\"\n",
    "    Calculate dynamic class weights based on the performance of the model on the current labelled data.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_labelled)\n",
    "    \n",
    "    # Find misclassifications (or measure uncertainty)\n",
    "    misclassifications = (y_pred != y_labeled)\n",
    "    \n",
    "    # Calculate the frequency of misclassifications per class\n",
    "    class_misclassifications = {class_label: np.sum(misclassifications[y_labeled == class_label]) \n",
    "                                for class_label in np.unique(y_labeled)}\n",
    "    \n",
    "    # Compute class weights as the inverse of misclassifications (more misclassified = higher weight)\n",
    "    total_misclassifications = sum(class_misclassifications.values())\n",
    "    class_weights = {class_label: (total_misclassifications / (class_misclassifications[class_label] + 1)) \n",
    "                     for class_label in class_misclassifications}\n",
    "    \n",
    "    return class_weights\n",
    "\n",
    "def select_samples(probalility, df, n_samples, labels, metric, class_weights):\n",
    "    \"\"\"\n",
    "    Select samples for active learning based on different uncertainty metrics and dynamically calculated class weights.\n",
    "\n",
    "    Parameters:\n",
    "    - probalility: Array of probabilities for each sample (shape: [n_samples, n_classes]).\n",
    "    - df: The DataFrame containing the feature data.\n",
    "    - n_samples: The number of samples to select.\n",
    "    - labels: The true labels for the unlabelled samples.\n",
    "    - metric: The uncertainty metric to use. Options are 'least_confidence', 'entropy', or 'margin_sampling'.\n",
    "    - calculate_class_weights_fn: A function to dynamically calculate class weights.\n",
    "\n",
    "    Returns:\n",
    "    - X_top: The feature data for the selected samples.\n",
    "    - y_top: The labels for the selected samples.\n",
    "    - X_rest: The feature data for the remaining samples.\n",
    "    - y_rest: The labels for the remaining samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a DataFrame to store the probabilities and labels\n",
    "    df_with_proba = df.copy()\n",
    "    df_with_proba['labels'] = labels\n",
    "    \n",
    "    # Compute the uncertainty scores based on the chosen metric\n",
    "    if metric == \"least_confidence\":\n",
    "        # Least Confidence: Select the samples with the lowest top predicted probabilities\n",
    "        prob_top = np.max(probalility, axis=1)  # Get the top probability for each sample\n",
    "        df_with_proba['uncertainty'] = prob_top\n",
    "\n",
    "    elif metric == \"entropy\":\n",
    "        # Entropy: Calculate the entropy for each sample based on its class probabilities\n",
    "        entropy_values = -np.sum(probalility * np.log(probalility + 1e-10), axis=1)  # Adding small epsilon to avoid log(0)\n",
    "        df_with_proba['uncertainty'] = entropy_values\n",
    "\n",
    "    elif metric == \"margin_sampling\":\n",
    "        # Margin Sampling: Select the samples where the top two predicted probabilities are closest\n",
    "        top_2_probs = np.partition(probalility, -2, axis=1)[:, -2:]  # Get the top 2 predicted probabilities\n",
    "        margin = top_2_probs[:, 1] - top_2_probs[:, 0]  # Calculate the difference between the top two\n",
    "        df_with_proba['uncertainty'] = margin\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown metric: {metric}. Available options are 'least_confidence', 'entropy', 'margin_sampling'.\")\n",
    "\n",
    "    # Apply class weighting to the uncertainty values if class weights are provided\n",
    "    if class_weights:\n",
    "        df_with_proba['uncertainty'] *= df_with_proba['labels'].map(class_weights)\n",
    "    \n",
    "    # Sort the samples by the uncertainty (ascending order to get the most uncertain samples)\n",
    "    df_with_proba = df_with_proba.sort_values(by='uncertainty', ascending=True)\n",
    "    \n",
    "    # Select the top `n_samples` samples with the highest uncertainty\n",
    "    df_top = df_with_proba[:n_samples]\n",
    "    X_top = df_top.drop(columns=['uncertainty', 'labels'])\n",
    "    y_top = df_top['labels']\n",
    "    \n",
    "    # Select the remaining samples\n",
    "    df_rest = df_with_proba[n_samples:]\n",
    "    X_rest = df_rest.drop(columns=['uncertainty', 'labels'])\n",
    "    y_rest = df_rest['labels']\n",
    "    \n",
    "    return X_top, y_top, X_rest, y_rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved for cycle 0 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.5571, Recall=0.5065, F1-score=0.5306\n",
      "Class good: Precision=0.2857, Recall=0.1429, F1-score=0.1905\n",
      "Class unacc: Precision=0.8769, Recall=0.9421, F1-score=0.9084\n",
      "Class vgood: Precision=0.4444, Recall=0.3077, F1-score=0.3636\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 39   4  30   4]\n",
      " [ 11   2   1   0]\n",
      " [ 13   0 228   1]\n",
      " [  7   1   1   4]]\n",
      "\n",
      "Overall Accuracy: 0.7890\n",
      "0.7890173410404624\n",
      "188\n",
      "Metrics saved for cycle 1 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.6154, Recall=0.7273, F1-score=0.6667\n",
      "Class good: Precision=0.2000, Recall=0.1429, F1-score=0.1667\n",
      "Class unacc: Precision=0.9409, Recall=0.9215, F1-score=0.9311\n",
      "Class vgood: Precision=0.3750, Recall=0.2308, F1-score=0.2857\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 56   4  14   3]\n",
      " [ 10   2   0   2]\n",
      " [ 18   1 223   0]\n",
      " [  7   3   0   3]]\n",
      "\n",
      "Overall Accuracy: 0.8208\n",
      "0.8208092485549133\n",
      "238\n",
      "Metrics saved for cycle 2 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.7808, Recall=0.7403, F1-score=0.7600\n",
      "Class good: Precision=0.3529, Recall=0.4286, F1-score=0.3871\n",
      "Class unacc: Precision=0.9553, Recall=0.9711, F1-score=0.9631\n",
      "Class vgood: Precision=0.4000, Recall=0.3077, F1-score=0.3478\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 57   7  10   3]\n",
      " [  4   6   1   3]\n",
      " [  7   0 235   0]\n",
      " [  5   4   0   4]]\n",
      "\n",
      "Overall Accuracy: 0.8728\n",
      "0.8728323699421965\n",
      "288\n",
      "Metrics saved for cycle 3 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.6250, Recall=0.5195, F1-score=0.5674\n",
      "Class good: Precision=0.2941, Recall=0.3571, F1-score=0.3226\n",
      "Class unacc: Precision=0.9157, Recall=0.9421, F1-score=0.9287\n",
      "Class vgood: Precision=0.0625, Recall=0.0769, F1-score=0.0690\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 40   7  21   9]\n",
      " [  4   5   0   5]\n",
      " [ 13   0 228   1]\n",
      " [  7   5   0   1]]\n",
      "\n",
      "Overall Accuracy: 0.7919\n",
      "0.791907514450867\n",
      "338\n",
      "Metrics saved for cycle 4 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.6782, Recall=0.7662, F1-score=0.7195\n",
      "Class good: Precision=0.4286, Recall=0.4286, F1-score=0.4286\n",
      "Class unacc: Precision=0.9658, Recall=0.9339, F1-score=0.9496\n",
      "Class vgood: Precision=0.3636, Recall=0.3077, F1-score=0.3333\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 59   4   8   6]\n",
      " [  7   6   0   1]\n",
      " [ 16   0 226   0]\n",
      " [  5   4   0   4]]\n",
      "\n",
      "Overall Accuracy: 0.8526\n",
      "0.8526011560693642\n",
      "388\n",
      "Metrics saved for cycle 5 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.6782, Recall=0.7662, F1-score=0.7195\n",
      "Class good: Precision=0.3077, Recall=0.2857, F1-score=0.2963\n",
      "Class unacc: Precision=0.9661, Recall=0.9421, F1-score=0.9540\n",
      "Class vgood: Precision=0.3000, Recall=0.2308, F1-score=0.2609\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 59   4   8   6]\n",
      " [  9   4   0   1]\n",
      " [ 14   0 228   0]\n",
      " [  5   5   0   3]]\n",
      "\n",
      "Overall Accuracy: 0.8497\n",
      "0.8497109826589595\n",
      "438\n",
      "Metrics saved for cycle 6 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.7632, Recall=0.7532, F1-score=0.7582\n",
      "Class good: Precision=0.5294, Recall=0.6429, F1-score=0.5806\n",
      "Class unacc: Precision=0.9628, Recall=0.9628, F1-score=0.9628\n",
      "Class vgood: Precision=0.3636, Recall=0.3077, F1-score=0.3333\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 58   4   9   6]\n",
      " [  4   9   0   1]\n",
      " [  9   0 233   0]\n",
      " [  5   4   0   4]]\n",
      "\n",
      "Overall Accuracy: 0.8786\n",
      "0.8786127167630058\n",
      "488\n",
      "Metrics saved for cycle 7 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.7808, Recall=0.7403, F1-score=0.7600\n",
      "Class good: Precision=0.5000, Recall=0.7143, F1-score=0.5882\n",
      "Class unacc: Precision=0.9587, Recall=0.9587, F1-score=0.9587\n",
      "Class vgood: Precision=0.3636, Recall=0.3077, F1-score=0.3333\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 57   4  10   6]\n",
      " [  3  10   0   1]\n",
      " [ 10   0 232   0]\n",
      " [  3   6   0   4]]\n",
      "\n",
      "Overall Accuracy: 0.8757\n",
      "0.8757225433526011\n",
      "538\n",
      "Metrics saved for cycle 8 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.7671, Recall=0.7273, F1-score=0.7467\n",
      "Class good: Precision=0.4348, Recall=0.7143, F1-score=0.5405\n",
      "Class unacc: Precision=0.9625, Recall=0.9545, F1-score=0.9585\n",
      "Class vgood: Precision=0.3000, Recall=0.2308, F1-score=0.2609\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 56   6   9   6]\n",
      " [  3  10   0   1]\n",
      " [ 11   0 231   0]\n",
      " [  3   7   0   3]]\n",
      "\n",
      "Overall Accuracy: 0.8671\n",
      "0.8670520231213873\n",
      "588\n",
      "Metrics saved for cycle 9 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8429, Recall=0.7662, F1-score=0.8027\n",
      "Class good: Precision=0.5789, Recall=0.7857, F1-score=0.6667\n",
      "Class unacc: Precision=0.9630, Recall=0.9669, F1-score=0.9649\n",
      "Class vgood: Precision=0.5714, Recall=0.6154, F1-score=0.5926\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 59   4   9   5]\n",
      " [  2  11   0   1]\n",
      " [  8   0 234   0]\n",
      " [  1   4   0   8]]\n",
      "\n",
      "Overall Accuracy: 0.9017\n",
      "0.9017341040462428\n",
      "638\n",
      "Metrics saved for cycle 10 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8507, Recall=0.7403, F1-score=0.7917\n",
      "Class good: Precision=0.6111, Recall=0.7857, F1-score=0.6875\n",
      "Class unacc: Precision=0.9553, Recall=0.9711, F1-score=0.9631\n",
      "Class vgood: Precision=0.5333, Recall=0.6154, F1-score=0.5714\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 57   3  11   6]\n",
      " [  2  11   0   1]\n",
      " [  7   0 235   0]\n",
      " [  1   4   0   8]]\n",
      "\n",
      "Overall Accuracy: 0.8988\n",
      "0.8988439306358381\n",
      "688\n",
      "Metrics saved for cycle 11 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8158, Recall=0.8052, F1-score=0.8105\n",
      "Class good: Precision=0.6667, Recall=0.7143, F1-score=0.6897\n",
      "Class unacc: Precision=0.9587, Recall=0.9587, F1-score=0.9587\n",
      "Class vgood: Precision=0.6154, Recall=0.6154, F1-score=0.6154\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 62   2   9   4]\n",
      " [  2  10   1   1]\n",
      " [ 10   0 232   0]\n",
      " [  2   3   0   8]]\n",
      "\n",
      "Overall Accuracy: 0.9017\n",
      "0.9017341040462428\n",
      "738\n",
      "Metrics saved for cycle 12 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8286, Recall=0.7532, F1-score=0.7891\n",
      "Class good: Precision=0.6667, Recall=0.8571, F1-score=0.7500\n",
      "Class unacc: Precision=0.9467, Recall=0.9545, F1-score=0.9506\n",
      "Class vgood: Precision=0.5714, Recall=0.6154, F1-score=0.5926\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 58   2  12   5]\n",
      " [  0  12   1   1]\n",
      " [ 11   0 231   0]\n",
      " [  1   4   0   8]]\n",
      "\n",
      "Overall Accuracy: 0.8931\n",
      "0.8930635838150289\n",
      "788\n",
      "Metrics saved for cycle 13 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8310, Recall=0.7662, F1-score=0.7973\n",
      "Class good: Precision=0.6667, Recall=0.8571, F1-score=0.7500\n",
      "Class unacc: Precision=0.9506, Recall=0.9545, F1-score=0.9526\n",
      "Class vgood: Precision=0.5714, Recall=0.6154, F1-score=0.5926\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 59   2  11   5]\n",
      " [  0  12   1   1]\n",
      " [ 11   0 231   0]\n",
      " [  1   4   0   8]]\n",
      "\n",
      "Overall Accuracy: 0.8960\n",
      "0.8959537572254336\n",
      "838\n",
      "Metrics saved for cycle 14 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8451, Recall=0.7792, F1-score=0.8108\n",
      "Class good: Precision=0.6471, Recall=0.7857, F1-score=0.7097\n",
      "Class unacc: Precision=0.9472, Recall=0.9628, F1-score=0.9549\n",
      "Class vgood: Precision=0.6667, Recall=0.6154, F1-score=0.6400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 60   2  12   3]\n",
      " [  1  11   1   1]\n",
      " [  9   0 233   0]\n",
      " [  1   4   0   8]]\n",
      "\n",
      "Overall Accuracy: 0.9017\n",
      "0.9017341040462428\n",
      "888\n",
      "Metrics saved for cycle 15 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8611, Recall=0.8052, F1-score=0.8322\n",
      "Class good: Precision=0.7647, Recall=0.9286, F1-score=0.8387\n",
      "Class unacc: Precision=0.9588, Recall=0.9628, F1-score=0.9608\n",
      "Class vgood: Precision=0.7143, Recall=0.7692, F1-score=0.7407\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 62   2  10   3]\n",
      " [  0  13   0   1]\n",
      " [  9   0 233   0]\n",
      " [  1   2   0  10]]\n",
      "\n",
      "Overall Accuracy: 0.9191\n",
      "0.9190751445086706\n",
      "938\n",
      "Metrics saved for cycle 16 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8971, Recall=0.7922, F1-score=0.8414\n",
      "Class good: Precision=0.6842, Recall=0.9286, F1-score=0.7879\n",
      "Class unacc: Precision=0.9593, Recall=0.9752, F1-score=0.9672\n",
      "Class vgood: Precision=0.6923, Recall=0.6923, F1-score=0.6923\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 61   3  10   3]\n",
      " [  0  13   0   1]\n",
      " [  6   0 236   0]\n",
      " [  1   3   0   9]]\n",
      "\n",
      "Overall Accuracy: 0.9220\n",
      "0.9219653179190751\n",
      "988\n",
      "Metrics saved for cycle 17 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8696, Recall=0.7792, F1-score=0.8219\n",
      "Class good: Precision=0.7222, Recall=0.9286, F1-score=0.8125\n",
      "Class unacc: Precision=0.9551, Recall=0.9669, F1-score=0.9610\n",
      "Class vgood: Precision=0.7143, Recall=0.7692, F1-score=0.7407\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 60   3  11   3]\n",
      " [  0  13   0   1]\n",
      " [  8   0 234   0]\n",
      " [  1   2   0  10]]\n",
      "\n",
      "Overall Accuracy: 0.9162\n",
      "0.9161849710982659\n",
      "1038\n",
      "Metrics saved for cycle 18 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8767, Recall=0.8312, F1-score=0.8533\n",
      "Class good: Precision=0.7333, Recall=0.7857, F1-score=0.7586\n",
      "Class unacc: Precision=0.9672, Recall=0.9752, F1-score=0.9712\n",
      "Class vgood: Precision=0.7143, Recall=0.7692, F1-score=0.7407\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 64   2   8   3]\n",
      " [  2  11   0   1]\n",
      " [  6   0 236   0]\n",
      " [  1   2   0  10]]\n",
      "\n",
      "Overall Accuracy: 0.9277\n",
      "0.9277456647398844\n",
      "1088\n",
      "Metrics saved for cycle 19 to custom_AL.csv\n",
      "Class-wise Precision, Recall, F1-score:\n",
      "Class acc: Precision=0.8889, Recall=0.8312, F1-score=0.8591\n",
      "Class good: Precision=0.7059, Recall=0.8571, F1-score=0.7742\n",
      "Class unacc: Precision=0.9671, Recall=0.9711, F1-score=0.9691\n",
      "Class vgood: Precision=0.6429, Recall=0.6923, F1-score=0.6667\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 64   2   8   3]\n",
      " [  0  12   0   2]\n",
      " [  7   0 235   0]\n",
      " [  1   3   0   9]]\n",
      "\n",
      "Overall Accuracy: 0.9249\n",
      "0.9248554913294798\n",
      "1138\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "X_labelled, X_unlabelled, y_labeled, y_unlabelled = train_test_split(X_train, y_train, test_size=0.9, stratify=y_train)\n",
    "\n",
    "# encode variables with ordinal encoding\n",
    "\n",
    "encoder = ce.OrdinalEncoder(cols=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'])\n",
    "X_labelled = encoder.fit_transform(X_labelled)\n",
    "X_test = encoder.transform(X_test)\n",
    "X_unlabelled = encoder.transform(X_unlabelled)\n",
    "\n",
    "\n",
    "# Whole budget\n",
    "B =1000\n",
    "# Budget per cycle\n",
    "b = 50\n",
    "# Number of cycle\n",
    "c = 0\n",
    "\n",
    "while B>0:\n",
    "    dt_clf = DecisionTreeClassifier(criterion='gini', max_depth=100, random_state=0)\n",
    "    dt_clf.fit(X_labelled, y_labeled)\n",
    "    probalilities = dt_clf.predict_proba(X_unlabelled)\n",
    "    class_weights = calculate_dynamic_class_weights_based_on_model(dt_clf, X_labelled, y_labeled)\n",
    "    #X_lowest_prob, y_lowest_proba, X_rest, y_rest = select_lowest_probabieties(probalility=probalilities, df=X_unlabelled, n_samples=b, labels=y_unlabelled)\n",
    "    X_lowest_prob, y_lowest_proba, X_rest, y_rest = select_samples(probalility=probalilities, df=X_unlabelled, n_samples=b, labels=y_unlabelled, metric='margin_sampling', class_weights=class_weights)\n",
    "\n",
    "    X_labelled = pd.concat([X_labelled, X_lowest_prob])\n",
    "    y_labeled = pd.concat([y_labeled, y_lowest_proba])\n",
    "    X_unlabelled = X_rest\n",
    "    y_unlabelled = y_rest\n",
    "    # Calculate accuracy for this cycle\n",
    "    y_pred = dt_clf.predict(X_test)\n",
    "    metrics_filename = 'custom_AL.csv'\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision, recall, f1, cm, accuracy = calculate_metrics(y_test, y_pred)\n",
    "    \n",
    "    # Save the metrics to the file\n",
    "    save_metrics_to_file(metrics_filename, c, precision, recall, f1, cm, accuracy, X_labelled)\n",
    "    # Compute precision, recall, and f1-score for each class\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    \n",
    "    # Print Precision, Recall, and F1 for each class\n",
    "    print(\"Class-wise Precision, Recall, F1-score:\")\n",
    "    for i, class_label in enumerate(np.unique(y_test)):\n",
    "        print(f\"Class {class_label}: Precision={precision[i]:.4f}, Recall={recall[i]:.4f}, F1-score={f1[i]:.4f}\")\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Optionally, you can also print overall accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")\n",
    "    print(accuracy)\n",
    "    print(X_labelled.shape[0])\n",
    "    c +=1\n",
    "    B -=b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
